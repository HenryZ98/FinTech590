{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f79cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import linalg as LA\n",
    "from scipy.stats import t\n",
    "from scipy.stats import norm\n",
    "import yfinance as yf\n",
    "import seaborn as sns\n",
    "import datetime as dt\n",
    "from pandas_datareader import data as pdr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27251e6a",
   "metadata": {},
   "source": [
    "<font size=\"5\">**Covariance estimation techniques**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8c350c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ewm (x, exp_w, lamda):\n",
    "    w = []\n",
    "    sum_w = 0\n",
    "    n = x.shape[1]\n",
    "    for i in range(1, len(x.index)+1):\n",
    "        w.append((1-lamda)*lamda**(i-1))\n",
    "        sum_w = sum_w + w[i-1]\n",
    "    for i in range(len(x.index)):   \n",
    "        exp_w.append(w[i] / sum_w)\n",
    "    \n",
    "    \n",
    "    cov_matrix = np.zeros([n,n])\n",
    "    col_mean = []\n",
    "    for i in range(n):\n",
    "        col_mean[i] = np.mean(x.iloc[:, i])\n",
    "        \n",
    "    for i in range (len(x.index)):\n",
    "        for j in range (n):\n",
    "            x.iloc[i,j] = x.iloc[i,j] - col_mean[j]\n",
    "    \n",
    "            \n",
    "    for i in range (n):\n",
    "        for j in range (n):\n",
    "            temp = exp_w * x.iloc[:,i]\n",
    "            cov_matrix[i,j] = np.dot(temp, x.iloc[:, j])\n",
    "            \n",
    "    return cov_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4a37a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCumm_var(x, lamb):\n",
    "    exp_w = []\n",
    "    cov_matrix = ewm(x, exp_w, lamb)\n",
    "    v1, w1 = LA.eigh(cov_matrix)\n",
    "    \n",
    "    tot = 0\n",
    "    for i in range(len(v1)):\n",
    "        tot += v1[i]\n",
    "    v1 = v1[::-1]\n",
    "    \n",
    "    cumu_var = []\n",
    "    k=1\n",
    "    for i in range(len(v1)):\n",
    "        sum_v = 0\n",
    "        for j in range(k):\n",
    "            sum_v += v1[j]\n",
    "        cumu_var.append(sum_v / tot)\n",
    "        k = k + 1\n",
    "    return cumu_var"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0d4c14",
   "metadata": {},
   "source": [
    "<font size=\"5\">**Non PSD fixes for correlation matrices**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ed61f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_psd(x):\n",
    "    return np.all(LA.eigvals(x) >= -1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de905b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nearPSD(A, epsilon=0):\n",
    "    n = A.shape[0]\n",
    "    invSD = None\n",
    "    out = A.copy()\n",
    "    A_diag = np.diag(A)\n",
    "    \n",
    "    #convert cov to cor matrix\n",
    "    if (np.count_nonzero(A_diag == 1) != n):\n",
    "        invSD = np.diag(np.divide(1, np.sqrt(A_diag)))\n",
    "        out = invSD * out * invSD\n",
    "    \n",
    "    eigval, eigvec = LA.eigh(out)\n",
    "    val = np.matrix(np.maximum(eigval, epsilon))\n",
    "    vec = np.matrix(eigvec)\n",
    "    \n",
    "    T = 1/(np.multiply(vec,vec) * val.T)\n",
    "    T = np.matrix(np.sqrt(np.diag(np.array(T).reshape((n)))))\n",
    "    B = T * vec * np.diag(np.array(np.sqrt(val)).reshape((n)))\n",
    "    out = B * B.T\n",
    "    print(invSD)\n",
    "    \n",
    "    if invSD != None:\n",
    "        invSD_diag = np.diag(invSD)\n",
    "        invSD = np.diag(np.divide(1, np.sqrt(invSD_diag)))\n",
    "        out = invSD * out * invSD\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f1c286",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Higham2002\n",
    "def _getAplus(A):\n",
    "    eigval, eigvec = LA.eigh(A)\n",
    "    Q = np.matrix(eigvec)\n",
    "    xdiag = np.matrix(np.diag(np.maximum(eigval, 0)))\n",
    "    return eigvec @ xdiag @ eigvec.T\n",
    "\n",
    "def _getPs(A, W=None):\n",
    "    W05 = np.matrix(W**.5)\n",
    "    iW = W05.I\n",
    "    return  iW @ _getAplus(W05 @ A @ W05) @ iW\n",
    "\n",
    "def _getPu(A, W=None):\n",
    "    Aret = A.copy()\n",
    "    for i in range(0, A.shape[0]):\n",
    "        Aret[i,i] = 1\n",
    "    return Aret\n",
    "\n",
    "def _wgtNorm(A, W = None):\n",
    "    W05 = np.sqrt(W)\n",
    "    W05 = W05 @ A @ W05\n",
    "    return (W05 * W05).sum()\n",
    "\n",
    "def hig_nearPSD(pc, W = None, epsilon = 1e-9, maxIter = 100, tol = 1e-9):\n",
    "    n = pc.shape[0]\n",
    "    if W == None:\n",
    "        W = np.identity(n)\n",
    "        \n",
    "    deltaS = np.zeros((n,n))\n",
    "    \n",
    "    Yk = pc.copy()\n",
    "    norml = 9999999\n",
    "    i = 1\n",
    "    \n",
    "    while i <= maxIter:\n",
    "        Rk = Yk - deltaS\n",
    "        Xk = _getPs(Rk, W)\n",
    "        deltaS = Xk - Rk\n",
    "        Yk = _getPu(Xk, W)\n",
    "        norm = _wgtNorm(Yk - pc, W)\n",
    "        \n",
    "        w, v = LA.eigh(Yk)\n",
    "        minEigVal = np.min(w)\n",
    "        \n",
    "        if ((norm - norml) < tol) and (minEigVal > -epsilon):\n",
    "            break\n",
    "            \n",
    "        norml = norm\n",
    "        i = i + 1\n",
    "        \n",
    "    if i < maxIter:\n",
    "        print(\"Converged in %d iterations.\\n\" % i)\n",
    "    else:\n",
    "        print(\"Converged failed after %d iterations.\\n\" % (i-1))\n",
    "        \n",
    "    return Yk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad469156",
   "metadata": {},
   "outputs": [],
   "source": [
    "def F_norm (cov, cov_psd):\n",
    "    temp = cov - cov_psd\n",
    "    return LA.norm(temp, 'fro')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86fce70",
   "metadata": {},
   "source": [
    "<font size=\"5\">**VaR calculation methods**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1fd558cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7abefbcc",
   "metadata": {},
   "source": [
    "Normal and T VaR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51dbb532",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_VaR(portofolioReturns, portfolioStd, distribution='normal', alpha=5, dof=6):\n",
    "    if distribution == 'normal':\n",
    "        VaR = norm.ppf(1-alpha/100)*portfolioStd - portofolioReturns\n",
    "    elif distribution == 't-distribution':\n",
    "        nu = dof\n",
    "        VaR = np.sqrt((nu-2)/nu) * t.ppf(1-alpha/100, nu) * portfolioStd - portofolioReturns\n",
    "    else:\n",
    "        raise TypeError(\"Expected distribution type 'normal'/'t-distribution'\")\n",
    "    return VaR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5101ae0c",
   "metadata": {},
   "source": [
    "Monte Carlo VaR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02207d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _mcVaR(returns, alpha):\n",
    "    # first check wheather returns is series\n",
    "    if isinstance(returns, pd.Series):\n",
    "        return np.percentile(returns, alpha)\n",
    "    else:\n",
    "        raise TypeError(\"You need to input a series.\")\n",
    "\n",
    "def mc_VaR (returns, mc_sim, time, alpha):\n",
    "    meanReturns = returns.mean()\n",
    "    covMatrix = returns.cov()\n",
    "    \n",
    "    covMatrix = near_psd(np.array(covMatrix))\n",
    "    #covMatrix = covMatrix\n",
    "    \n",
    "    weights = np.random.random(len(meanReturns))\n",
    "    weights /= np.sum(weights) # normalize the weight\n",
    "    \n",
    "\n",
    "    meanMatrix = np.full(shape = (time, len(weights)), fill_value = meanReturns)\n",
    "    meanMatrix = meanMatrix.T\n",
    "\n",
    "    portfolio_sim = np.full(shape = (time, mc_sim), fill_value = 0)\n",
    "\n",
    "    # MC loop\n",
    "\n",
    "    # we can set a initial value of portofolio to see the absolute value\n",
    "    # initial_money = 10000\n",
    "    for m in range(mc_sim):\n",
    "        '''\n",
    "        Here we assume that daily return are distributed by a multvariate normal distribution\n",
    "        Using Cholesky Decomposition, we get L, which is lower triangle.\n",
    "        return = mean + L * Z, where Z is normal distribution (0,1)\n",
    "        '''\n",
    "        Z = np.random.normal(size = (time, len(weights)))\n",
    "        L = np.linalg.cholesky(covMatrix)\n",
    "        dailyReturns = meanMatrix + np.inner(L, Z)\n",
    "\n",
    "        portfolio_sim[:,m] = np.cumprod(np.inner(weights, dailyReturns.T) + 1) # FV = PV * (1 + r)^t\n",
    "\n",
    "    lastDay_return = portfolio_sim[-1,:]\n",
    "    _mcVaR(lastDay_return, alpha = alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70e9635",
   "metadata": {},
   "source": [
    "Historical VaR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a47e628",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data function\n",
    "def get_data (stocks, start, end):\n",
    "    stockData = yf.download(stocks, start, end)['Adj Close']\n",
    "    returns = stockData.pct_change()\n",
    "    meanReturns = returns.mean()\n",
    "    covMatrix = returns.cov()\n",
    "    returns = returns.dropna()\n",
    "    return returns, meanReturns, covMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e053b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data by choosing what stocks you want to add and start and end date\n",
    "stockList = ['TSLA', 'NIO', 'BYD', 'XPEV', 'LI', 'GM']\n",
    "endDate = dt.datetime.now()\n",
    "startDate = dt.datetime(2021,1,1)\n",
    "\n",
    "returns, meanReturns, covMatrix = get_data(stockList, startDate, endDate)\n",
    "print(meanReturns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4857c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a random weight on each stocks\n",
    "weights = np.random.random(len(meanReturns))\n",
    "weights /= np.sum(weights) # normalize the weight\n",
    "\n",
    "returns['portfolio'] = returns.dot(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89546e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def histVaR (returns, alpha):\n",
    "    if isinstance(returns, pd.Series):\n",
    "        return np.percentile(returns, alpha)\n",
    "    \n",
    "    #for here, we use aggregate to calculate the each column's VaR\n",
    "    elif isinstance(returns, pd.DataFrame):\n",
    "        return returns.aggregate(histVaR, alpha = alpha)\n",
    "    \n",
    "    else:\n",
    "        raise TypeError(\"You need to input series or dataframe.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca925ef",
   "metadata": {},
   "source": [
    "<font size=\"5\">**ES calculation**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fcea29c",
   "metadata": {},
   "source": [
    "Normal and T CVaR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8686906",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_CVaR(portofolioReturns, portfolioStd, distribution='normal', alpha=5, dof=6):\n",
    "    if distribution == 'normal':\n",
    "        CVaR = (alpha/100)**-1 * norm.pdf(norm.ppf(alpha/100))*portfolioStd - portofolioReturns\n",
    "    elif distribution == 't-distribution':\n",
    "        nu = dof\n",
    "        xanu = t.ppf(alpha/100, nu)\n",
    "        CVaR = -1/(alpha/100) * (1-nu)**(-1) * (nu-2+xanu**2) * t.pdf(xanu, nu) * portfolioStd - portofolioReturns\n",
    "    else:\n",
    "        raise TypeError(\"Expected distribution type 'normal'/'t-distribution'\")\n",
    "    return CVaR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c09d99",
   "metadata": {},
   "source": [
    "Monte Carlo CVaR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd834f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _mcCVaR(returns, alpha):\n",
    "    # first check wheather returns is series\n",
    "    if isinstance(returns, pd.Series):\n",
    "        belowVaR = returns <= mcVaR(returns, alpha = alpha)\n",
    "        return returns[belowVaR].mean()\n",
    "    else:\n",
    "        raise TypeError(\"You need to input a series.\")\n",
    "        \n",
    "        \n",
    "def mc_CVaR (returns, mc_sim, time, alpha):\n",
    "    meanReturns = returns.mean()\n",
    "    covMatrix = returns.cov()\n",
    "    \n",
    "    covMatrix = near_psd(np.array(covMatrix))\n",
    "    #covMatrix = covMatrix\n",
    "    \n",
    "    weights = np.random.random(len(meanReturns))\n",
    "    weights /= np.sum(weights) # normalize the weight\n",
    "    \n",
    "\n",
    "    meanMatrix = np.full(shape = (time, len(weights)), fill_value = meanReturns)\n",
    "    meanMatrix = meanMatrix.T\n",
    "\n",
    "    portfolio_sim = np.full(shape = (time, mc_sim), fill_value = 0)\n",
    "\n",
    "    # MC loop\n",
    "\n",
    "    # we can set a initial value of portofolio to see the absolute value\n",
    "    # initial_money = 10000\n",
    "    for m in range(mc_sim):\n",
    "        '''\n",
    "        Here we assume that daily return are distributed by a multvariate normal distribution\n",
    "        Using Cholesky Decomposition, we get L, which is lower triangle.\n",
    "        return = mean + L * Z, where Z is normal distribution (0,1)\n",
    "        '''\n",
    "        Z = np.random.normal(size = (time, len(weights)))\n",
    "        L = np.linalg.cholesky(covMatrix)\n",
    "        dailyReturns = meanMatrix + np.inner(L, Z)\n",
    "\n",
    "        portfolio_sim[:,m] = np.cumprod(np.inner(weights, dailyReturns.T) + 1) # FV = PV * (1 + r)^t\n",
    "\n",
    "    lastDay_return = portfolio_sim[-1,:]\n",
    "    _mcCVaR(lastDay_return, alpha = alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6901117b",
   "metadata": {},
   "source": [
    "Historical CVaR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801f1122",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CVaR function\n",
    "def histCVaR (returns, alpha):\n",
    "    if isinstance(returns, pd.Series):\n",
    "        belowVaR = returns <= histVaR(returns, alpha = alpha)\n",
    "        return returns[belowVaR].mean()\n",
    "    \n",
    "    #for here, we use aggregate to calculate the each column's VaR\n",
    "    elif isinstance(returns, pd.DataFrame):\n",
    "        return returns.aggregate(histCVaR, alpha = alpha)\n",
    "    \n",
    "    else:\n",
    "        raise TypeError(\"You need to input series or dataframe.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
